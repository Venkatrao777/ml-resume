{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5d076b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "import google.genai as genai\n",
    "from key import my_sk\n",
    "\n",
    "from markdown import markdown\n",
    "from weasyprint import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b1513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Venkat Rao \n",
       "**Email**: [vvr750@gmail.com](mailto:vvr750@gmail.com)  \n",
       "**LinkedIn**: [VenkatRao](https://www.linkedin.com/in/venkat-rao-295647368))  \n",
       "\n",
       "---\n",
       "\n",
       "## Technical Skills  \n",
       "- **Tools**: Python, SQL, GitHub, AWS (SageMaker), Snowflake, Julia  \n",
       "- **Certifications**:  AWS Cloud Practitioner Essentials (AWS), Data Structure & Algorithms (Udemy), Tableau (Udemy)  \n",
       "\n",
       "## Work Experience\n",
       "\n",
       "### **Founder**  \n",
       "**The Data Entrepreneurs** | Plano, Texas *(January 2023 - Present)*  \n",
       "- Founded a community of 900+ data & AI entrepreneurs. Hosting monthly workshops and podcast episodes.\n",
       "\n",
       "### **Content Creator**  \n",
       "**YouTube** | Plano, Texas *(September 2020 - Present)*  \n",
       "- Making videos on Data Science + Entrepreneurship. 1M+ Views. 35k+ subs.\n",
       "\n",
       "### **Writer**  \n",
       "**Towards Data Science** | Plano, Texas *(November 2020 - Present)*  \n",
       "- Writing articles on Data Science + AI. 25k Monthly Reads. 16k Followers.\n",
       "\n",
       "### **Data Science Consultant**  \n",
       "**Shawhin Talebi Ventures LLC** | Plano, Texas *(December 2020 - Present)*  \n",
       "- Implemented full data pipeline for novel study evaluating the impact of over 300 biometrics variables on human performance in live-fire training scenarios which uncovered link between EEG activity and performance.  \n",
       "- Applied unsupervised learning approaches to longitudinal ICU data to discover sepsis sub-phenotypes.  \n",
       "\n",
       "### **Data Scientist**  \n",
       "**Toyota Financial Services** | Plano, Texas *(June 2022 - July 2023)*  \n",
       "- Uncovered and corrected issue in a pre-existing production credit risk model that impacted over 70% accounts and wrote model monitoring scripts to help avoid future failures.  \n",
       "- Redeveloped loan originations model for independent dealers which resulted in a 50% model performance improvement and provided $2.5 million in realized value to business partner.  \n",
       "\n",
       "### **Research Assistant**  \n",
       "**The University of Texas at Dallas (Department of Physics)** | Richardson, Texas *(December 2018 - May 2022)*  \n",
       "- Published open-source methodology to discover optimal EEG bands which led to better characterization of the underlying power spectrum than the more commonly used band boundaries by a factor of 2.  \n",
       "- Trained over 100 machine learning models to estimate particulate matter (PM) concentrations based on a suite of over 300 biometric variables, achieving high fidelity (r² = 0.91).  \n",
       "- Led 5 teams focused on deployment of a real-time Python-based biometrics application, unveiling immediate insights that were previously inaccessible.  \n",
       "\n",
       "## Education  \n",
       "**California State University, Fullerton**  - Masters of Science - *2016*  \n",
       "**JNTUH College of Engineering,Hyderabad** - Bachelor's of Technology - *2014*  \n",
       "\n",
       "## Awards and Honors  \n",
       "- **2021 Friends of BrainHealth Visionary New Scientist Award** — Finalist *(September 2021)*  \n",
       "- **2nd Annual Weeks of Welcome Poster Competition** — 3rd Place Winner *(August 2019)*  \n",
       "- **Outstanding Undergraduate Student** — Nominee *(April 2017)*  \n",
       "- **Student Leader of the Year** — Nominee *(April 2017)*\n",
       "---\n",
       "\n",
       "**References and additional information available upon request.**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open and read the Markdown file\n",
    "with open(\"Resumes/venkat_resume.md\", \"r\", encoding=\"utf-8\") as file:\n",
    "    resume_string = file.read()\n",
    "\n",
    "# display resume\n",
    "display(Markdown(resume_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5999fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input job description\n",
    "jd_string = \"This is where the job description needs to be entered\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f628943",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = lambda resume_string, jd_string : f\"\"\"\n",
    "You are a professional resume optimization expert specializing in tailoring resumes to specific job descriptions. Your goal is to optimize my resume and provide actionable suggestions for improvement to align with the target role.\n",
    "\n",
    "### Guidelines:\n",
    "1. **Relevance**:  \n",
    "   - Prioritize experiences, skills, and achievements **most relevant to the job description**.  \n",
    "   - Remove or de-emphasize irrelevant details to ensure a **concise** and **targeted** resume.\n",
    "   - Limit work experience section to 2-3 most relevant roles\n",
    "   - Limit bullet points under each role to 2-3 most relevant impacts\n",
    "\n",
    "2. **Action-Driven Results**:  \n",
    "   - Use **strong action verbs** and **quantifiable results** (e.g., percentages, revenue, efficiency improvements) to highlight impact.  \n",
    "\n",
    "3. **Keyword Optimization**:  \n",
    "   - Integrate **keywords** and phrases from the job description naturally to optimize for ATS (Applicant Tracking Systems).  \n",
    "\n",
    "4. **Additional Suggestions** *(If Gaps Exist)*:  \n",
    "   - If the resume does not fully align with the job description, suggest:  \n",
    "     1. **Additional technical or soft skills** that I could add to make my profile stronger.  \n",
    "     2. **Certifications or courses** I could pursue to bridge the gap.  \n",
    "     3. **Project ideas or experiences** that would better align with the role.  \n",
    "\n",
    "5. **Formatting**:  \n",
    "   - Output the tailored resume in **clean Markdown format**.  \n",
    "   - Include an **\"Additional Suggestions\"** section at the end with actionable improvement recommendations.  \n",
    "\n",
    "---\n",
    "\n",
    "### Input:\n",
    "- **My resume**:  \n",
    "{resume_string}\n",
    "\n",
    "- **The job description**:  \n",
    "{jd_string}\n",
    "\n",
    "---\n",
    "\n",
    "### Output:  \n",
    "1. **Tailored Resume**:  \n",
    "   - A resume in **Markdown format** that emphasizes relevant experience, skills, and achievements.  \n",
    "   - Incorporates job description **keywords** to optimize for ATS.  \n",
    "   - Uses strong language and is no longer than **one page**.\n",
    "\n",
    "2. **Additional Suggestions** *(if applicable)*:  \n",
    "   - List **skills** that could strengthen alignment with the role.  \n",
    "   - Recommend **certifications or courses** to pursue.  \n",
    "   - Suggest **specific projects or experiences** to develop.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dac8835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template(resume_string, jd_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d203fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide the **Job Description** for the target role. I need this crucial information to effectively tailor your resume, identify relevant keywords, and provide precise optimization suggestions.\n",
      "\n",
      "Without a specific job description, I cannot fulfill the core request of aligning your resume to a target role, as the optimization process is heavily dependent on the requirements and responsibilities outlined in the job posting.\n",
      "\n",
      "**Once you provide the Job Description, I will proceed with:**\n",
      "\n",
      "1.  **A highly tailored, one-page resume** in Markdown format, focusing on the 2-3 most relevant roles and 2-3 impactful bullet points per role, using action verbs and quantifiable results, and integrating keywords from the job description.\n",
      "2.  **Specific, actionable suggestions** for additional skills, certifications, or projects to bridge any gaps identified between your current profile and the target role's requirements.\n",
      "\n",
      "---\n",
      "\n",
      "### Placeholder for Tailored Resume (Example Structure - Awaiting Job Description)\n",
      "\n",
      "Below is an *example* of how your resume would be structured and optimized for a **hypothetical** \"Senior Data Scientist\" role, demonstrating the conciseness and focus I would apply. This is not the final optimized resume, as it lacks the specific keywords and relevance prioritization from an actual job description.\n",
      "\n",
      "```markdown\n",
      "# Venkat Rao\n",
      "**Email**: [vvr750@gmail.com](mailto:vvr750@gmail.com) | **LinkedIn**: [VenkatRao](https://www.linkedin.com/in/venkat-rao-295647368)\n",
      "\n",
      "## Summary\n",
      "Highly accomplished Data Scientist with 5+ years of experience in developing and deploying advanced machine learning models, optimizing data pipelines, and deriving actionable insights from complex datasets. Proven ability to translate business challenges into data-driven solutions, significantly impacting financial performance and operational efficiency. Expertise in Python, SQL, and cloud platforms like AWS, with a strong foundation in statistical analysis and unsupervised learning.\n",
      "\n",
      "## Technical Skills\n",
      "- **Programming**: Python, SQL, Julia\n",
      "- **Cloud & Tools**: AWS (SageMaker), Snowflake, GitHub\n",
      "- **Concepts**: Machine Learning, Statistical Modeling, Data Pipelining, Unsupervised Learning, Credit Risk Modeling\n",
      "\n",
      "## Work Experience\n",
      "\n",
      "### **Data Scientist**\n",
      "**Toyota Financial Services** | Plano, Texas *(June 2022 - July 2023)*\n",
      "- Redeveloped loan originations model for independent dealers, achieving a **50% model performance improvement** and generating **$2.5 million in realized value**.\n",
      "- Identified and resolved a critical issue in a production credit risk model affecting **over 70% of accounts**, implementing robust monitoring scripts to prevent future failures.\n",
      "\n",
      "### **Data Science Consultant**\n",
      "**Shawhin Talebi Ventures LLC** | Plano, Texas *(December 2020 - Present)*\n",
      "- Implemented a comprehensive data pipeline for a novel study, evaluating 300+ biometric variables to uncover links between EEG activity and human performance.\n",
      "- Applied unsupervised learning techniques to longitudinal ICU data, successfully discovering novel sepsis sub-phenotypes.\n",
      "\n",
      "### **Research Assistant**\n",
      "**The University of Texas at Dallas (Department of Physics)** | Richardson, Texas *(December 2018 - May 2022)*\n",
      "- Developed and deployed a real-time Python-based biometrics application, providing immediate insights from complex data streams.\n",
      "- Trained over 100 machine learning models to estimate particulate matter concentrations with high fidelity (r² = 0.91) using 300+ biometric variables.\n",
      "\n",
      "## Education\n",
      "**California State University, Fullerton** - Masters of Science - *2016*\n",
      "**JNTUH College of Engineering, Hyderabad** - Bachelor's of Technology - *2014*\n",
      "\n",
      "## Awards and Honors\n",
      "- **2021 Friends of BrainHealth Visionary New Scientist Award** — Finalist *(September 2021)*\n",
      "\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Additional Suggestions (To be customized upon Job Description receipt)\n",
      "\n",
      "Once the Job Description is provided, this section will include highly specific and actionable recommendations to further strengthen your profile for the target role.\n",
      "\n",
      "**Example (for a hypothetical \"Senior Data Scientist\" role focused on MLOps/Deployment):**\n",
      "\n",
      "1.  **Additional Technical Skills**:\n",
      "    *   **Containerization**: Docker, Kubernetes (often crucial for model deployment and scalability).\n",
      "    *   **CI/CD Tools**: Jenkins, GitLab CI/CD, GitHub Actions (for automated testing and deployment pipelines).\n",
      "    *   **MLOps Platforms**: MLflow, Kubeflow, Sagemaker MLOps capabilities (beyond just SageMaker for training).\n",
      "    *   **Big Data Technologies**: Spark, Hadoop (if the role involves processing very large datasets).\n",
      "\n",
      "2.  **Certifications or Courses**:\n",
      "    *   **AWS Certified Machine Learning – Specialty**: Demonstrates advanced knowledge in designing, implementing, and maintaining ML solutions on AWS.\n",
      "    *   **Google Cloud Professional Machine Learning Engineer**: Similar to AWS, but for GCP.\n",
      "    *   **Coursera/Udemy Courses**: \"MLOps Specialization,\" \"Deep Learning Specialization\" (if deep learning is a core requirement).\n",
      "\n",
      "3.  **Project Ideas or Experiences**:\n",
      "    *   **End-to-End ML Project**: Develop a project that goes beyond model training to include data versioning, model versioning, continuous integration, continuous deployment, and monitoring in a cloud environment (e.g., deploying a Flask/FastAPI app with a model on AWS Lambda/EC2, setting up monitoring with CloudWatch).\n",
      "    *   **Contribution to Open Source MLOps Tool**: Contribute to a relevant open-source library to showcase practical application of MLOps principles.\n",
      "    *   **Performance Optimization Project**: Detail a project where you specifically optimized the inference speed or resource consumption of a deployed model.\n",
      "\n",
      "---\n",
      "\n",
      "**Please provide the Job Description now, and I will generate your optimized resume and detailed suggestions!**\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=my_sk,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash\",  # or another Gemini model of your choice\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Expert resume writer\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response_string = response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(response_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80ea8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = response_string.split(\"## Additional Suggestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76fd3974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide the **Job Description** for the target role. I need this crucial information to effectively tailor your resume, identify relevant keywords, and provide precise optimization suggestions.\n",
       "\n",
       "Without a specific job description, I cannot fulfill the core request of aligning your resume to a target role, as the optimization process is heavily dependent on the requirements and responsibilities outlined in the job posting.\n",
       "\n",
       "**Once you provide the Job Description, I will proceed with:**\n",
       "\n",
       "1.  **A highly tailored, one-page resume** in Markdown format, focusing on the 2-3 most relevant roles and 2-3 impactful bullet points per role, using action verbs and quantifiable results, and integrating keywords from the job description.\n",
       "2.  **Specific, actionable suggestions** for additional skills, certifications, or projects to bridge any gaps identified between your current profile and the target role's requirements.\n",
       "\n",
       "---\n",
       "\n",
       "### Placeholder for Tailored Resume (Example Structure - Awaiting Job Description)\n",
       "\n",
       "Below is an *example* of how your resume would be structured and optimized for a **hypothetical** \"Senior Data Scientist\" role, demonstrating the conciseness and focus I would apply. This is not the final optimized resume, as it lacks the specific keywords and relevance prioritization from an actual job description.\n",
       "\n",
       "```markdown\n",
       "# Venkat Rao\n",
       "**Email**: [vvr750@gmail.com](mailto:vvr750@gmail.com) | **LinkedIn**: [VenkatRao](https://www.linkedin.com/in/venkat-rao-295647368)\n",
       "\n",
       "## Summary\n",
       "Highly accomplished Data Scientist with 5+ years of experience in developing and deploying advanced machine learning models, optimizing data pipelines, and deriving actionable insights from complex datasets. Proven ability to translate business challenges into data-driven solutions, significantly impacting financial performance and operational efficiency. Expertise in Python, SQL, and cloud platforms like AWS, with a strong foundation in statistical analysis and unsupervised learning.\n",
       "\n",
       "## Technical Skills\n",
       "- **Programming**: Python, SQL, Julia\n",
       "- **Cloud & Tools**: AWS (SageMaker), Snowflake, GitHub\n",
       "- **Concepts**: Machine Learning, Statistical Modeling, Data Pipelining, Unsupervised Learning, Credit Risk Modeling\n",
       "\n",
       "## Work Experience\n",
       "\n",
       "### **Data Scientist**\n",
       "**Toyota Financial Services** | Plano, Texas *(June 2022 - July 2023)*\n",
       "- Redeveloped loan originations model for independent dealers, achieving a **50% model performance improvement** and generating **$2.5 million in realized value**.\n",
       "- Identified and resolved a critical issue in a production credit risk model affecting **over 70% of accounts**, implementing robust monitoring scripts to prevent future failures.\n",
       "\n",
       "### **Data Science Consultant**\n",
       "**Shawhin Talebi Ventures LLC** | Plano, Texas *(December 2020 - Present)*\n",
       "- Implemented a comprehensive data pipeline for a novel study, evaluating 300+ biometric variables to uncover links between EEG activity and human performance.\n",
       "- Applied unsupervised learning techniques to longitudinal ICU data, successfully discovering novel sepsis sub-phenotypes.\n",
       "\n",
       "### **Research Assistant**\n",
       "**The University of Texas at Dallas (Department of Physics)** | Richardson, Texas *(December 2018 - May 2022)*\n",
       "- Developed and deployed a real-time Python-based biometrics application, providing immediate insights from complex data streams.\n",
       "- Trained over 100 machine learning models to estimate particulate matter concentrations with high fidelity (r² = 0.91) using 300+ biometric variables.\n",
       "\n",
       "## Education\n",
       "**California State University, Fullerton** - Masters of Science - *2016*\n",
       "**JNTUH College of Engineering, Hyderabad** - Bachelor's of Technology - *2014*\n",
       "\n",
       "## Awards and Honors\n",
       "- **2021 Friends of BrainHealth Visionary New Scientist Award** — Finalist *(September 2021)*\n",
       "\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "#"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f3bd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as PDF\n",
    "output_pdf_file = \"Resumes/resume_new.pdf\"\n",
    "\n",
    "# Convert Markdown to HTML\n",
    "html_content = markdown(response_list[0])\n",
    "\n",
    "# Convert HTML to PDF and save\n",
    "HTML(string=html_content).write_pdf(output_pdf_file, stylesheets=['Resumes/style.css'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d7f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as markdown\n",
    "output_file = \"Resumes/resume_new.md\"\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(response_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48c55ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " (To be customized upon Job Description receipt)\n",
       "\n",
       "Once the Job Description is provided, this section will include highly specific and actionable recommendations to further strengthen your profile for the target role.\n",
       "\n",
       "**Example (for a hypothetical \"Senior Data Scientist\" role focused on MLOps/Deployment):**\n",
       "\n",
       "1.  **Additional Technical Skills**:\n",
       "    *   **Containerization**: Docker, Kubernetes (often crucial for model deployment and scalability).\n",
       "    *   **CI/CD Tools**: Jenkins, GitLab CI/CD, GitHub Actions (for automated testing and deployment pipelines).\n",
       "    *   **MLOps Platforms**: MLflow, Kubeflow, Sagemaker MLOps capabilities (beyond just SageMaker for training).\n",
       "    *   **Big Data Technologies**: Spark, Hadoop (if the role involves processing very large datasets).\n",
       "\n",
       "2.  **Certifications or Courses**:\n",
       "    *   **AWS Certified Machine Learning – Specialty**: Demonstrates advanced knowledge in designing, implementing, and maintaining ML solutions on AWS.\n",
       "    *   **Google Cloud Professional Machine Learning Engineer**: Similar to AWS, but for GCP.\n",
       "    *   **Coursera/Udemy Courses**: \"MLOps Specialization,\" \"Deep Learning Specialization\" (if deep learning is a core requirement).\n",
       "\n",
       "3.  **Project Ideas or Experiences**:\n",
       "    *   **End-to-End ML Project**: Develop a project that goes beyond model training to include data versioning, model versioning, continuous integration, continuous deployment, and monitoring in a cloud environment (e.g., deploying a Flask/FastAPI app with a model on AWS Lambda/EC2, setting up monitoring with CloudWatch).\n",
       "    *   **Contribution to Open Source MLOps Tool**: Contribute to a relevant open-source library to showcase practical application of MLOps principles.\n",
       "    *   **Performance Optimization Project**: Detail a project where you specifically optimized the inference speed or resource consumption of a deployed model.\n",
       "\n",
       "---\n",
       "\n",
       "**Please provide the Job Description now, and I will generate your optimized resume and detailed suggestions!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_list[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
